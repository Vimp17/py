{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDRk9y3bQOHpIcrkHIMhfM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vimp17/py/blob/main/Bidirectional_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2jeU9sddfIjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a94732-f35d-4f79-f930-e8939537efa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natasha\n",
            "  Downloading natasha-1.6.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting pymorphy2 (from natasha)\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting razdel>=0.5.0 (from natasha)\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting navec>=0.9.0 (from natasha)\n",
            "  Downloading navec-0.10.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting slovnet>=0.6.0 (from natasha)\n",
            "  Downloading slovnet-0.6.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting yargy>=0.16.0 (from natasha)\n",
            "  Downloading yargy-0.16.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting ipymarkup>=0.8.0 (from natasha)\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting intervaltree>=3 (from ipymarkup>=0.8.0->natasha)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from navec>=0.9.0->natasha) (1.26.4)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2->natasha)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2->natasha)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2->natasha)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree>=3->ipymarkup>=0.8.0->natasha)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Downloading natasha-1.6.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yargy-0.16.0-py3-none-any.whl (33 kB)\n",
            "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: docopt, intervaltree\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c33c24e37218500bc048c06924bf8e6b2955e409354e1bfaeefc0a84244b600c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=01680bebd7c441c1e04ffcc33036b0bbf2d8b5c9154a7b6eee583bd70a02be1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
            "Successfully built docopt intervaltree\n",
            "Installing collected packages: sortedcontainers, razdel, pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.6.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.6.0 sortedcontainers-2.4.0 yargy-0.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip install natasha"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from navec import Navec\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms.v2 as tfs_v2\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class PhraseDataset(data.Dataset):\n",
        "    def __init__(self, path_true, path_false, navec_emb, batch_size=8):\n",
        "        self.navec_emb = navec_emb\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        with open(path_true, 'r', encoding='utf-8') as f:\n",
        "            phrase_true = f.readlines()\n",
        "            self._clear_phrase(phrase_true)\n",
        "\n",
        "        with open(path_false, 'r', encoding='utf-8') as f:\n",
        "            phrase_false = f.readlines()\n",
        "            self._clear_phrase(phrase_false)\n",
        "\n",
        "        self.phrase_lst = [(_x, 0) for _x in phrase_true] + [(_x, 1) for _x in phrase_false]\n",
        "        self.phrase_lst.sort(key=lambda _x: len(_x[0]))\n",
        "        self.dataset_len = len(self.phrase_lst)\n",
        "\n",
        "    def _clear_phrase(self, p_lst):\n",
        "        for _i, _p in enumerate(p_lst):\n",
        "            _p = _p.lower().replace('\\ufeff', '').strip()\n",
        "            _p = re.sub(r'[^А-яA-z- ]', '', _p)\n",
        "            _words = _p.split()\n",
        "            _words = [w for w in _words if w in self.navec_emb]\n",
        "            p_lst[_i] = _words\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        item *= self.batch_size\n",
        "        item_last = item + self.batch_size\n",
        "        if item_last > self.dataset_len:\n",
        "            item_last = self.dataset_len\n",
        "\n",
        "        _data = []\n",
        "        _target = []\n",
        "        max_length = len(self.phrase_lst[item_last-1][0])\n",
        "\n",
        "        for i in range(item, item_last):\n",
        "            words_emb = []\n",
        "            phrase = self.phrase_lst[i]\n",
        "            length = len(phrase[0])\n",
        "\n",
        "            for k in range(max_length):\n",
        "                t = torch.tensor(self.navec_emb[phrase[0][k]], dtype=torch.float32) if k < length else torch.zeros(300)\n",
        "                words_emb.append(t)\n",
        "\n",
        "            _data.append(torch.vstack(words_emb))\n",
        "            _target.append(torch.tensor(phrase[1], dtype=torch.float32))\n",
        "\n",
        "        _data_batch = torch.stack(_data)\n",
        "        _target = torch.vstack(_target)\n",
        "        return _data_batch, _target\n",
        "\n",
        "    def __len__(self):\n",
        "        last = 0 if self.dataset_len % self.batch_size == 0 else 1\n",
        "        return self.dataset_len // self.batch_size + last\n",
        "\n",
        "\n",
        "class WordsRNN(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.hidden_size = 16\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.rnn = nn.RNN(in_features, self.hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.out = nn.Linear(self.hidden_size * 2, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, h = self.rnn(x)\n",
        "        hh = torch.cat((h[-2, :, :], h[-1, :, :]), dim=1)\n",
        "        y = self.out(hh)\n",
        "        return y"
      ],
      "metadata": {
        "id": "00Qz1Om9gCX1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
        "navec = Navec.load(path)\n",
        "\n",
        "d_train = PhraseDataset(\"/content/train_data_true.txt\", \"/content/train_data_false.txt\", navec)\n",
        "train_data = data.DataLoader(d_train, batch_size=1, shuffle=True)\n",
        "\n",
        "model = WordsRNN(300, 1)\n",
        "\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.001, weight_decay=0.001)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "epochs = 20\n",
        "model.train()\n",
        "\n",
        "for _e in range(epochs):\n",
        "    loss_mean = 0\n",
        "    lm_count = 0\n",
        "\n",
        "    train_tqdm = tqdm(train_data, leave=True)\n",
        "    for x_train, y_train in train_tqdm:\n",
        "        predict = model(x_train.squeeze(0)).squeeze(0)\n",
        "        loss = loss_func(predict, y_train.squeeze(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        lm_count += 1\n",
        "        loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
        "        train_tqdm.set_description(f\"Epoch [{_e+1}/{epochs}], loss_mean={loss_mean:.3f}\")\n",
        "\n",
        "st = model.state_dict()\n",
        "torch.save(st, 'model_rnn_bidir.tar')"
      ],
      "metadata": {
        "id": "Q8mZsw1afP27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3cad93-a289-41ab-be50-cab0bf3cc098"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/20], loss_mean=0.709: 100%|██████████| 22/22 [00:00<00:00, 52.65it/s]\n",
            "Epoch [2/20], loss_mean=0.636: 100%|██████████| 22/22 [00:00<00:00, 122.41it/s]\n",
            "Epoch [3/20], loss_mean=0.580: 100%|██████████| 22/22 [00:00<00:00, 68.77it/s] \n",
            "Epoch [4/20], loss_mean=0.530: 100%|██████████| 22/22 [00:00<00:00, 60.34it/s]\n",
            "Epoch [5/20], loss_mean=0.467: 100%|██████████| 22/22 [00:00<00:00, 61.05it/s]\n",
            "Epoch [6/20], loss_mean=0.411: 100%|██████████| 22/22 [00:00<00:00, 58.12it/s]\n",
            "Epoch [7/20], loss_mean=0.349: 100%|██████████| 22/22 [00:00<00:00, 73.61it/s]\n",
            "Epoch [8/20], loss_mean=0.284: 100%|██████████| 22/22 [00:00<00:00, 94.44it/s]\n",
            "Epoch [9/20], loss_mean=0.227: 100%|██████████| 22/22 [00:00<00:00, 52.44it/s]\n",
            "Epoch [10/20], loss_mean=0.169: 100%|██████████| 22/22 [00:00<00:00, 68.09it/s]\n",
            "Epoch [11/20], loss_mean=0.138: 100%|██████████| 22/22 [00:00<00:00, 92.91it/s]\n",
            "Epoch [12/20], loss_mean=0.102: 100%|██████████| 22/22 [00:00<00:00, 53.73it/s]\n",
            "Epoch [13/20], loss_mean=0.077: 100%|██████████| 22/22 [00:00<00:00, 76.16it/s]\n",
            "Epoch [14/20], loss_mean=0.072: 100%|██████████| 22/22 [00:00<00:00, 79.28it/s]\n",
            "Epoch [15/20], loss_mean=0.049: 100%|██████████| 22/22 [00:00<00:00, 52.10it/s]\n",
            "Epoch [16/20], loss_mean=0.043: 100%|██████████| 22/22 [00:00<00:00, 48.22it/s]\n",
            "Epoch [17/20], loss_mean=0.031: 100%|██████████| 22/22 [00:00<00:00, 29.68it/s]\n",
            "Epoch [18/20], loss_mean=0.024: 100%|██████████| 22/22 [00:00<00:00, 41.63it/s]\n",
            "Epoch [19/20], loss_mean=0.021: 100%|██████████| 22/22 [00:00<00:00, 36.91it/s]\n",
            "Epoch [20/20], loss_mean=0.017: 100%|██████████| 22/22 [00:00<00:00, 41.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "phrase = \"Я чувствую себя неплохо\"\n",
        "phrase_lst = phrase.lower().split()\n",
        "phrase_lst = [torch.tensor(navec[w]) for w in phrase_lst if w in navec]\n",
        "_data_batch = torch.stack(phrase_lst)\n",
        "predict = model(_data_batch.unsqueeze(0)).squeeze(0)\n",
        "p = torch.nn.functional.sigmoid(predict).item()\n",
        "print(p)\n",
        "print(phrase, \":\", \"положительное\" if p < 0.5 else \"отрицательное\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi_vt737fTAU",
        "outputId": "4fd4196b-9161-4099-b67e-3582a9d30243"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16313587129116058\n",
            "Я чувствую себя неплохо : положительное\n"
          ]
        }
      ]
    }
  ]
}