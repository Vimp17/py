{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQoQSRe8hchHn5kiWUCSRc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vimp17/py/blob/main/TransferLearningmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCP4pko5MSxK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path  = \"/content/dogs\"\n",
        "train = True\n",
        "p = path = os.path.join(path, \"train/\" if train else \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50 transferlearning on dogs pictures"
      ],
      "metadata": {
        "id": "QKjB8CCEMiIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torchvision import models\n",
        "import torchvision.transforms.v2 as tfs_v2\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class DogDataset(data.Dataset):\n",
        "    def __init__(self, path, train=True, transform=None):\n",
        "        self.path = os.path.join(path, \"train\" if train else \"test\")\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(os.path.join(self.path, \"format.json\"), \"r\") as fp:\n",
        "            self.format = json.load(fp)\n",
        "\n",
        "        self.length = 0\n",
        "        self.files = []\n",
        "        self.targets = torch.eye(10)\n",
        "\n",
        "        for _dir, _target in self.format.items():\n",
        "            path = os.path.join(self.path, _dir)\n",
        "            list_files = os.listdir(path)\n",
        "            self.length += len(list_files)\n",
        "            self.files.extend(map(lambda _x: (os.path.join(path, _x), _target), list_files))\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        path_file, target = self.files[item]\n",
        "        t = self.targets[target]\n",
        "        img = Image.open(path_file)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, t\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "resnet_weights = models.ResNet50_Weights.DEFAULT\n",
        "transforms = resnet_weights.transforms()\n",
        "\n",
        "model = models.resnet50(weights=resnet_weights)\n",
        "model.requires_grad_(False)\n",
        "model.fc = nn.Linear(512*4, 10)\n",
        "model.fc.requires_grad_(True)\n",
        "\n",
        "d_train = DogDataset(\"/content/dogs\", transform=transforms)\n",
        "train_data = data.DataLoader(d_train, batch_size=32, shuffle=True)\n",
        "\n",
        "optimizer = optim.Adam(params=model.fc.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "epochs = 15\n",
        "model.train()\n",
        "\n",
        "for _e in range(epochs):\n",
        "    loss_mean = 0\n",
        "    lm_count = 0\n",
        "\n",
        "    train_tqdm = tqdm(train_data,leave=True)\n",
        "    for x_train, y_train in train_tqdm:\n",
        "        predict = model(x_train)\n",
        "        loss = loss_func(predict, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        lm_count += 1\n",
        "        loss_mean = 1/lm_count *loss.item() + (1 - 1/lm_count) * loss.item()\n",
        "        train_tqdm.set_description(f\"Epoch [{_e+1}/ {epochs}], loss_mean :{loss_mean:.4f}\")\n",
        "\n",
        "st = model.state_dict()\n",
        "torch.save(st, \"model_transfer_learning_resnet.tar\")\n",
        "\n",
        "d_test = DogDataset(\"/content/dogs\", train=False, transform=transforms)\n",
        "test_data = data.DataLoader(d_test, batch_size = 64, shuffle=False)\n",
        "\n",
        "Q = 0\n",
        "P = 0\n",
        "count = 0\n",
        "model.eval()\n",
        "\n",
        "test_tqdm = tqdm(test_data, leave=True)\n",
        "for x_test, y_test in test_tqdm:\n",
        "    pre = model(x_test)\n",
        "    p2 = torch.argmax(pre, dim=1)\n",
        "    y = torch.argmax(y_test, dim=1)\n",
        "    P += torch.sum(p2==y).item()\n",
        "    Q += loss_func(pre, y_test).item()\n",
        "    count+=1\n",
        "\n",
        "Q /=count\n",
        "P /= len(d_test)\n",
        "print()\n",
        "print(Q)\n",
        "print(P)"
      ],
      "metadata": {
        "id": "WBQBh1A-MXAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch [1/ 15], loss_mean :1.7394: 100%|██████████| 51/51 [07:30<00:00,  8.84s/it]\n",
        "Epoch [2/ 15], loss_mean :0.6623: 100%|██████████| 51/51 [07:26<00:00,  8.75s/it]\n",
        "Epoch [3/ 15], loss_mean :0.6007: 100%|██████████| 51/51 [07:26<00:00,  8.76s/it]\n",
        "Epoch [4/ 15], loss_mean :1.0246: 100%|██████████| 51/51 [07:22<00:00,  8.68s/it]\n",
        "Epoch [5/ 15], loss_mean :1.1563: 100%|██████████| 51/51 [07:30<00:00,  8.83s/it]\n",
        "Epoch [6/ 15], loss_mean :0.8343: 100%|██████████| 51/51 [07:30<00:00,  8.84s/it]\n",
        "Epoch [7/ 15], loss_mean :1.2935: 100%|██████████| 51/51 [07:34<00:00,  8.91s/it]\n",
        "Epoch [8/ 15], loss_mean :0.7505: 100%|██████████| 51/51 [07:30<00:00,  8.84s/it]\n",
        "Epoch [9/ 15], loss_mean :0.6558: 100%|██████████| 51/51 [07:31<00:00,  8.85s/it]\n",
        "Epoch [10/ 15], loss_mean :1.3598: 100%|██████████| 51/51 [07:22<00:00,  8.68s/it]\n",
        "Epoch [11/ 15], loss_mean :0.8213: 100%|██████████| 51/51 [07:17<00:00,  8.58s/it]\n",
        "Epoch [12/ 15], loss_mean :0.5555: 100%|██████████| 51/51 [07:16<00:00,  8.57s/it]\n",
        "Epoch [13/ 15], loss_mean :0.5248: 100%|██████████| 51/51 [07:33<00:00,  8.88s/it]\n",
        "Epoch [14/ 15], loss_mean :0.6469: 100%|██████████| 51/51 [07:29<00:00,  8.82s/it]\n",
        "Epoch [15/ 15], loss_mean :0.2556: 100%|██████████| 51/51 [07:29<00:00,  8.82s/it]\n",
        "100%|██████████| 5/5 [01:27<00:00, 17.59s/it]\n",
        "0.1835356295108795\n",
        "0.9526813880126183"
      ],
      "metadata": {
        "id": "K_7eU5guMeN-"
      }
    }
  ]
}