{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+LRRsUYW2avM1Hs5RoCib",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vimp17/py/blob/main/CNN_REG_Sunposition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B1XI7sFUnHK"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Укажите путь к архиву и папку для распаковки\n",
        "archive_path = '/content/dataset_gen_reg.zip'  # Пример: '/content/drive/MyDrive/archive.zip'\n",
        "extract_folder = '/content/images'\n",
        "\n",
        "# Распаковка\n",
        "with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(\"Архив успешно распакован!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from random import randint\n",
        "import json\n",
        "import pygame\n",
        "\n",
        "train_data = {'total': 10000, 'dir': \"train\"}\n",
        "test_data = {'total': 1000, 'dir': \"test\"}\n",
        "total_bk = 10\n",
        "total_cls = 4\n",
        "dir_out = 'dataset_reg'\n",
        "file_format = 'format.json'\n",
        "cls = [(255, 255, 255), (0, 0, 255), (0, 255, 0), (255, 0, 0)]\n",
        "\n",
        "if not os.path.exists(dir_out):\n",
        "    os.mkdir(dir_out)\n",
        "    if not os.path.exists(os.path.join(dir_out, \"train\")):\n",
        "        os.mkdir(os.path.join(dir_out, \"train\"))\n",
        "    if not os.path.exists(os.path.join(dir_out, \"test\")):\n",
        "        os.mkdir(os.path.join(dir_out, \"test\"))\n",
        "\n",
        "sun = pygame.image.load(\"/content/images/dataset_gen_reg/images/sun64.png\")\n",
        "backs = [pygame.image.load(f\"/content/images/dataset_gen_reg/images/back_{n}.png\") for n in range(1, total_bk+1)]\n",
        "\n",
        "for info in (train_data, test_data):\n",
        "    sun_coords = dict()\n",
        "\n",
        "    for i in range(1, info['total']+1):\n",
        "        file_out = f\"sun_reg_{i}.png\"\n",
        "        im = backs[randint(0, total_bk-1)].copy()\n",
        "\n",
        "        for _ in range(randint(20, 100)):\n",
        "            x0 = randint(0, 256)\n",
        "            y0 = randint(0, 256)\n",
        "            pygame.draw.circle(im, cls[randint(0, total_cls-1)], (x0, y0), 1)\n",
        "\n",
        "        x = randint(32, 256 - 32)\n",
        "        y = randint(32, 256 - 32)\n",
        "        sun_coords[file_out] = (x, y)\n",
        "        im.blit(sun, (x-32, y-32))\n",
        "\n",
        "        pygame.image.save(im, os.path.join(dir_out, info['dir'], file_out))\n",
        "\n",
        "    fp = open(os.path.join(dir_out, info['dir'], file_format), \"w\")\n",
        "    json.dump(sun_coords, fp)\n",
        "    fp.close()\n"
      ],
      "metadata": {
        "id": "6S8ReqLEUvQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms.v2 as tfs\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class SunDataset(data.Dataset):\n",
        "    def __init__(self, path, train=True, transform=None):\n",
        "        self.path = os.path.join(path, \"train\" if train else \"test\")\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(os.path.join(self.path, \"format.json\"), \"r\") as fp:\n",
        "            self.format = json.load(fp)\n",
        "\n",
        "        self.length = len(self.format)\n",
        "        self.files = tuple(self.format.keys())\n",
        "        self.targets = tuple(self.format.values())\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        path_file = os.path.join(self.path, self.files[item])\n",
        "        img = Image.open(path_file).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, torch.tensor(self.targets[item], dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "transforms = tfs.Compose([tfs.ToImage(), tfs.ToDtype(torch.float32, scale=True)])\n",
        "d_train = SunDataset(\"dataset_reg\", transform=transforms)\n",
        "train_data = data.DataLoader(d_train, batch_size=32, shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(32, 8, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(8, 4, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(4096,128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 2)\n",
        "\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.001)\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "epochs = 5\n",
        "model.train()\n",
        "\n",
        "for i in range(epochs):\n",
        "    loss_mean = 0\n",
        "    lm_count = 0\n",
        "\n",
        "    train_tqdm = tqdm(train_data, leave=True)\n",
        "    for x_train, y_train in train_tqdm:\n",
        "         predict = model(x_train)\n",
        "         loss = loss_func(predict, y_train)\n",
        "\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "\n",
        "         lm_count += 1\n",
        "         loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
        "         train_tqdm.set_description(f\"Epoch [{i+1}/{epochs}], loss_mean={loss_mean:.3f}\")\n",
        "st = model.state_dict()\n",
        "torch.save(st, 'model_sun.tar')\n",
        "\n",
        "d_test = SunDataset(\"dataset_reg\", train=False, transform=transforms)\n",
        "test_data = data.DataLoader(d_test, batch_size=50, shuffle=False)\n",
        "\n",
        "Q = 0\n",
        "count = 0\n",
        "model.eval()\n",
        "\n",
        "test_tqdm = tqdm(test_data, leave=True)\n",
        "for x_test, y_test in test_tqdm:\n",
        "         with torch.no_grad():\n",
        "              pre = model(x_test)\n",
        "              Q += loss_func(pre, y_test).item()\n",
        "              count += 1\n",
        "\n",
        "Q /= count\n",
        "\n",
        "print(Q)\n",
        "\n"
      ],
      "metadata": {
        "id": "XWesrVCGUw-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.v2 as tfs\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#     nn.Conv2d(3, 32, 3, padding='same'),\n",
        "#     nn.ReLU(),\n",
        "#     nn.MaxPool2d(2),\n",
        "#     nn.Conv2d(32, 16, 3, padding='same'),\n",
        "#     nn.ReLU(),\n",
        "#     nn.MaxPool2d(2),\n",
        "#     nn.Conv2d(16, 8, 3, padding='same'),\n",
        "#     nn.ReLU(),\n",
        "#     nn.MaxPool2d(2),\n",
        "#     nn.Conv2d(8, 4, 3, padding='same'),\n",
        "#     nn.ReLU(),\n",
        "#     nn.MaxPool2d(2),\n",
        "#     nn.Flatten(),\n",
        "#     nn.Linear(1024, 256),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(256, 2)\n",
        "# )\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(32, 8, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(8, 4, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(4096, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 2)\n",
        ")\n",
        "\n",
        "path = 'dataset_reg/test/'\n",
        "num_img = 100\n",
        "\n",
        "st = torch.load('model_sun.tar', weights_only=False)\n",
        "model.load_state_dict(st)\n",
        "\n",
        "with open(os.path.join(path, \"format.json\"), \"r\") as fp:\n",
        "    format = json.load(fp)\n",
        "\n",
        "transforms = tfs.Compose([tfs.ToImage(), tfs.ToDtype(torch.float32, scale=True)])\n",
        "img = Image.open(os.path.join(path, f'sun_reg_{num_img}.png')).convert('RGB')\n",
        "img_t = transforms(img).unsqueeze(0)\n",
        "\n",
        "model.eval()\n",
        "predict = model(img_t)\n",
        "print(predict)\n",
        "print(tuple(format.values())[num_img-1])\n",
        "p = predict.detach().squeeze().numpy()\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.scatter(p[0], p[1], s=20, c='r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GUYocIYiUy7R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}