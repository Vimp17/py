{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNySG3ORILPRWv4tIUFQg/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vimp17/py/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jeU9sddfIjS"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Укажите путь к архиву и папку для распаковки\n",
        "archive_path = '/content/dataset_seg.zip'  # Пример: '/content/drive/MyDrive/archive.zip'\n",
        "extract_folder = '/content'\n",
        "\n",
        "# Распаковка\n",
        "with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(\"Архив успешно распакован!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import BatchSampler, SequentialSampler\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms.v2 as tfs_v2\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class CharsDataset(data.Dataset):\n",
        "    def __init__(self, path, prev_chars=3):\n",
        "        self.prev_chars = prev_chars\n",
        "\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            self.text = f.read()\n",
        "            self.text = self.text.replace('\\ufeff', '')  # убираем первый невидимый символ\n",
        "            self.text = re.sub(r'[^А-яA-z0-9.,?;: ]', '', self.text)  # заменяем все неразрешенные символы на пустые символы\n",
        "\n",
        "        self.text = self.text.lower()\n",
        "        self.alphabet = set(self.text)\n",
        "        self.int_to_alpha = dict(enumerate(sorted(self.alphabet)))\n",
        "        self.alpha_to_int = {b: a for a, b in self.int_to_alpha.items()}\n",
        "        # self.alphabet = {'а': 0, 'б': 1, 'в': 2, 'г': 3, 'д': 4, 'е': 5, 'ё': 6, 'ж': 7, 'з': 8, 'и': 9,\n",
        "        #                  'й': 10, 'к': 11, 'л': 12, 'м': 13, 'н': 14, 'о': 15, 'п': 16, 'р': 17, 'с': 18,\n",
        "        #                  'т': 19, 'у': 20, 'ф': 21, 'х': 22, 'ц': 23, 'ч': 24, 'ш': 25, 'щ': 26, 'ъ': 27,\n",
        "        #                  'ы': 28, 'ь': 29, 'э': 30, 'ю': 31, 'я': 32, ' ': 33, '.': 34, '!': 35, '?': 36}\n",
        "        self.num_characters = len(self.alphabet)\n",
        "        self.onehots = torch.eye(self.num_characters)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        _data = torch.vstack([self.onehots[self.alpha_to_int[self.text[x]]] for x in range(item, item+self.prev_chars)])\n",
        "        ch = self.text[item+self.prev_chars]\n",
        "        t = self.alpha_to_int[ch]\n",
        "        return _data, t\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text) - 1 - self.prev_chars\n",
        "\n",
        "\n",
        "class TextRNN(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.hidden_size = 64\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.rnn = nn.RNN(in_features, self.hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_size, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, h = self.rnn(x)\n",
        "        y = self.out(h)\n",
        "        return y\n",
        "\n",
        "\n",
        "d_train = CharsDataset(\"/content/train_data_true.txt\", prev_chars=10)\n",
        "train_data = data.DataLoader(d_train, batch_size=64, shuffle=False)\n",
        "\n",
        "model = TextRNN(d_train.num_characters, d_train.num_characters)\n",
        "\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 10000\n",
        "model.train()\n",
        "\n",
        "for _e in range(epochs):\n",
        "    loss_mean = 0\n",
        "    lm_count = 0\n",
        "\n",
        "    train_tqdm = tqdm(train_data, leave=True)\n",
        "    for x_train, y_train in train_tqdm:\n",
        "        predict = model(x_train).squeeze(0)\n",
        "        loss = loss_func(predict, y_train.long())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        lm_count += 1\n",
        "        loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
        "        train_tqdm.set_description(f\"Epoch [{_e+1}/{epochs}], loss_mean={loss_mean:.3f}\")\n",
        "        if (_e+1)%1000==0:\n",
        "           st = model.state_dict()\n",
        "           torch.save(st, 'model_rnn_1.tar')\n",
        "\n",
        "\n",
        "st = model.state_dict()\n",
        "torch.save(st, 'model_rnn_1.tar')"
      ],
      "metadata": {
        "id": "00Qz1Om9gCX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import BatchSampler, SequentialSampler\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms.v2 as tfs_v2\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class CharsDataset(data.Dataset):\n",
        "    def __init__(self, path, prev_chars=3):\n",
        "        self.prev_chars = prev_chars\n",
        "\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            self.text = f.read()\n",
        "            self.text = self.text.replace('\\ufeff', '')  # убираем первый невидимый символ\n",
        "            self.text = re.sub(r'[^А-яA-z0-9.,?;: ]', '', self.text)  # заменяем все неразрешенные символы на пустые символы\n",
        "\n",
        "        self.text = self.text.lower()\n",
        "        self.alphabet = set(self.text)\n",
        "        self.int_to_alpha = dict(enumerate(sorted(self.alphabet)))\n",
        "        self.alpha_to_int = {b: a for a, b in self.int_to_alpha.items()}\n",
        "        # self.alphabet = {'а': 0, 'б': 1, 'в': 2, 'г': 3, 'д': 4, 'е': 5, 'ё': 6, 'ж': 7, 'з': 8, 'и': 9,\n",
        "        #                  'й': 10, 'к': 11, 'л': 12, 'м': 13, 'н': 14, 'о': 15, 'п': 16, 'р': 17, 'с': 18,\n",
        "        #                  'т': 19, 'у': 20, 'ф': 21, 'х': 22, 'ц': 23, 'ч': 24, 'ш': 25, 'щ': 26, 'ъ': 27,\n",
        "        #                  'ы': 28, 'ь': 29, 'э': 30, 'ю': 31, 'я': 32, ' ': 33, '.': 34, '!': 35, '?': 36}\n",
        "        self.num_characters = len(self.alphabet)\n",
        "        self.onehots = torch.eye(self.num_characters)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        _data = torch.vstack([self.onehots[self.alpha_to_int[self.text[x]]] for x in range(item, item+self.prev_chars)])\n",
        "        ch = self.text[item+self.prev_chars]\n",
        "        t = self.alpha_to_int[ch]\n",
        "        return _data, t\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text) - 1 - self.prev_chars\n",
        "\n",
        "class TextRNN(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.hidden_size = 64\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.rnn = nn.RNN(in_features, self.hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_size, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, h = self.rnn(x)\n",
        "        y = self.out(h)\n",
        "        return y\n",
        "\n",
        "d_train = CharsDataset(\"/content/train_data_true.txt\", prev_chars=10)\n",
        "train_data = data.DataLoader(d_train, batch_size=64, shuffle=False)\n",
        "\n",
        "model = TextRNN(d_train.num_characters, d_train.num_characters)\n",
        "\n",
        "st = torch.load('/content/model_rnn_1_4000epochs.tar', weights_only=False)\n",
        "\n",
        "model.load_state_dict(st)\n",
        "model.eval()\n",
        "predict = \"Думайте позитивно и верьте\".lower()\n",
        "total = 40\n",
        "\n",
        "for _ in range(total):\n",
        "    _data = torch.vstack([d_train.onehots[d_train.alpha_to_int[predict[-x]]] for x in range(d_train.prev_chars, 0, -1)])\n",
        "    p = model(_data.unsqueeze(0)).squeeze(0)\n",
        "    indx = torch.argmax(p, dim=1)\n",
        "    predict += d_train.int_to_alpha[indx.item()]\n",
        "\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "Q8mZsw1afP27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1b79b3-c46b-4fa1-9721-d82470395ecf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "думайте позитивно и верьте в свою способности важны валинелыть вам\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = \"Мой дядя самых\".lower()\n",
        "total = 40\n",
        "\n",
        "for _ in range(total):\n",
        "    _data = torch.vstack([d_train.onehots[d_train.alpha_to_int[predict[-x]]] for x in range(d_train.prev_chars, 0, -1)])\n",
        "    p = model(_data.unsqueeze(0)).squeeze(0)\n",
        "    indx = torch.argmax(p, dim=1)\n",
        "    predict += d_train.int_to_alpha[indx.item()]\n",
        "\n",
        "print(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi_vt737fTAU",
        "outputId": "3893a102-f709-4bee-fa7c-bb92864bfc88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "мой дядя самых и славай циатроено долать ообелажимая д\n"
          ]
        }
      ]
    }
  ]
}